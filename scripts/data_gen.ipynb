{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15281c16",
   "metadata": {},
   "source": [
    "To gather user comments and other relevant information, we will employ the Python Reddit API Wrapper (PRAW) which builds upon the publically available reddit API in a user-friendly manner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d348eed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw\n",
    "import pandas as pd\n",
    "\n",
    "# initialize login-info\n",
    "reddit = praw.Reddit(\n",
    "    client_id=\"SgqCbXgBegHP1bRZ2qc7FQ\",\n",
    "    client_secret=\"OrSeWWIvWoOJl7WVniFKDlMSkvW-rQ\",\n",
    "    user_agent=\"macos:Sentiment_Analysis:v1 (by u/Minimum-Tadpole-5000)\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b685de1",
   "metadata": {},
   "source": [
    "The previous block initializes a read-only instance of reddit that can be used to access public subbreddits of interest for submissions, comments, redditors, etc. To perform meaningful analysis, we are motivated to create a CSV file of the data. The following code block does exactly that, manipulating the CommentForest object and gathering all comments through a breadth-first-search procedure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ae39f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "subreddit = reddit.subreddit(\"UCSantaBarbara\") # Define subreddit\n",
    "comments = [] # initialize comment list\n",
    "\n",
    "for submission in subreddit.top(limit=10): # Adjust type of post (top, hot, controversial, etc.) and number returned\n",
    "    submission.comments.replace_more(limit=None) # flatten nested comment structure\n",
    "    for comment in submission.comments.list():\n",
    "        comments.append({\n",
    "            \"id\": comment.id,\n",
    "            \"author\": str(comment.author),\n",
    "            \"body\": comment.body,\n",
    "            \"score\": comment.score,\n",
    "            \"created_utc\": comment.created_utc,\n",
    "            \"parent_id\": comment.parent_id,\n",
    "            \"link_id\": comment.link_id,\n",
    "            \"permalink\": comment.permalink,\n",
    "            \"is_submitter\": comment.is_submitter,\n",
    "            \"distinguished\": comment.distinguished,\n",
    "            \"stickied\": comment.stickied\n",
    "        })\n",
    "\n",
    "df = pd.DataFrame(comments)\n",
    "df.to_csv(\"../data/UCSantaBarbara-top-10.csv\") # save to .csv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca58439",
   "metadata": {},
   "source": [
    "This boilerplate code can easily be generalized into a function that takes in a string containing the name of a subreddit to scrape and the desired number of submissions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4f16ebc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_comments_as_csv(subreddit: str, num_submissions: int, sort_method: str):\n",
    "    sub = reddit.subreddit(subreddit) # Define subreddit\n",
    "    comments = [] # initialize comment list\n",
    "\n",
    "    # Use getattr to dynamically access the sort method\n",
    "    sort_type = getattr(sub, sort_method)\n",
    "\n",
    "    for submission in sort_type(limit=num_submissions): # Adjust type of post (top, hot, controversial, etc.) and number returned\n",
    "        submission.comments.replace_more(limit=None) # flatten nested comment structure\n",
    "        for comment in submission.comments.list():\n",
    "            comments.append({\n",
    "                \"id\": comment.id,\n",
    "                \"author\": str(comment.author),\n",
    "                \"body\": comment.body,\n",
    "                \"score\": comment.score,\n",
    "                \"comment_karma\": getattr(comment.author, \"comment_karma\", None),\n",
    "                \"created_utc\": comment.created_utc,\n",
    "                \"parent_id\": comment.parent_id,\n",
    "                \"link_id\": comment.link_id,\n",
    "                \"permalink\": comment.permalink,\n",
    "                \"is_submitter\": comment.is_submitter,\n",
    "                \"distinguished\": comment.distinguished,\n",
    "                \"stickied\": comment.stickied\n",
    "            })\n",
    "\n",
    "    df = pd.DataFrame(comments)\n",
    "    df.to_csv(f\"../data/{subreddit}-{sort_method}-{num_submissions}.csv\", index=False) # save to .csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a2dbb0",
   "metadata": {},
   "source": [
    "We can now focus our data collection on a certain subject across subreddits to analyze sentiment. For example, we can gather the comments from the top post of the UCSB, UCSD, UCD, UCLA, and UCI subreddits. Recall that gathering this data relies on the public reddit API, which can only handle so many requests at a time. It is important to respect the network and avoid overloading it with requests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d56aec44",
   "metadata": {},
   "outputs": [
    {
     "ename": "TooManyRequests",
     "evalue": "received 429 HTTP response",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTooManyRequests\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m get_comments_as_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUCSD\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m get_comments_as_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUCDavis\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m get_comments_as_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mucla\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m get_comments_as_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUCI\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[19], line 16\u001b[0m, in \u001b[0;36mget_comments_as_csv\u001b[0;34m(subreddit, num_submissions, sort_method)\u001b[0m\n\u001b[1;32m      9\u001b[0m     submission\u001b[38;5;241m.\u001b[39mcomments\u001b[38;5;241m.\u001b[39mreplace_more(limit\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;66;03m# flatten nested comment structure\u001b[39;00m\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m comment \u001b[38;5;129;01min\u001b[39;00m submission\u001b[38;5;241m.\u001b[39mcomments\u001b[38;5;241m.\u001b[39mlist():\n\u001b[1;32m     11\u001b[0m         comments\u001b[38;5;241m.\u001b[39mappend({\n\u001b[1;32m     12\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m: comment\u001b[38;5;241m.\u001b[39mid,\n\u001b[1;32m     13\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauthor\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mstr\u001b[39m(comment\u001b[38;5;241m.\u001b[39mauthor),\n\u001b[1;32m     14\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbody\u001b[39m\u001b[38;5;124m\"\u001b[39m: comment\u001b[38;5;241m.\u001b[39mbody,\n\u001b[1;32m     15\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscore\u001b[39m\u001b[38;5;124m\"\u001b[39m: comment\u001b[38;5;241m.\u001b[39mscore,\n\u001b[0;32m---> 16\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcomment_karma\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mgetattr\u001b[39m(comment\u001b[38;5;241m.\u001b[39mauthor, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcomment_karma\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m     17\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcreated_utc\u001b[39m\u001b[38;5;124m\"\u001b[39m: comment\u001b[38;5;241m.\u001b[39mcreated_utc,\n\u001b[1;32m     18\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparent_id\u001b[39m\u001b[38;5;124m\"\u001b[39m: comment\u001b[38;5;241m.\u001b[39mparent_id,\n\u001b[1;32m     19\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlink_id\u001b[39m\u001b[38;5;124m\"\u001b[39m: comment\u001b[38;5;241m.\u001b[39mlink_id,\n\u001b[1;32m     20\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpermalink\u001b[39m\u001b[38;5;124m\"\u001b[39m: comment\u001b[38;5;241m.\u001b[39mpermalink,\n\u001b[1;32m     21\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis_submitter\u001b[39m\u001b[38;5;124m\"\u001b[39m: comment\u001b[38;5;241m.\u001b[39mis_submitter,\n\u001b[1;32m     22\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdistinguished\u001b[39m\u001b[38;5;124m\"\u001b[39m: comment\u001b[38;5;241m.\u001b[39mdistinguished,\n\u001b[1;32m     23\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstickied\u001b[39m\u001b[38;5;124m\"\u001b[39m: comment\u001b[38;5;241m.\u001b[39mstickied\n\u001b[1;32m     24\u001b[0m         })\n\u001b[1;32m     26\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(comments)\n\u001b[1;32m     27\u001b[0m df\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../data/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msubreddit\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msort_method\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_submissions\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/praw/models/reddit/base.py:38\u001b[0m, in \u001b[0;36mRedditBase.__getattr__\u001b[0;34m(self, attribute)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Return the value of ``attribute``.\"\"\"\u001b[39;00m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m attribute\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fetched:\n\u001b[0;32m---> 38\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fetch()\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, attribute)\n\u001b[1;32m     40\u001b[0m msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattribute\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/praw/models/reddit/redditor.py:181\u001b[0m, in \u001b[0;36mRedditor._fetch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_fetch\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 181\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fetch_data()\n\u001b[1;32m    182\u001b[0m     data \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    183\u001b[0m     other \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reddit, _data\u001b[38;5;241m=\u001b[39mdata)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/praw/models/reddit/base.py:89\u001b[0m, in \u001b[0;36mRedditBase._fetch_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     87\u001b[0m name, fields, params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fetch_info()\n\u001b[1;32m     88\u001b[0m path \u001b[38;5;241m=\u001b[39m API_PATH[name]\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfields)\n\u001b[0;32m---> 89\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reddit\u001b[38;5;241m.\u001b[39mrequest(method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGET\u001b[39m\u001b[38;5;124m\"\u001b[39m, params\u001b[38;5;241m=\u001b[39mparams, path\u001b[38;5;241m=\u001b[39mpath)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/praw/util/deprecate_args.py:46\u001b[0m, in \u001b[0;36m_deprecate_args.<locals>.wrapper.<locals>.wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     39\u001b[0m     arg_string \u001b[38;5;241m=\u001b[39m _generate_arg_string(_old_args[: \u001b[38;5;28mlen\u001b[39m(args)])\n\u001b[1;32m     40\u001b[0m     warn(\n\u001b[1;32m     41\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPositional arguments for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m will no longer be\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     42\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m supported in PRAW 8.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mCall this function with \u001b[39m\u001b[38;5;132;01m{\u001b[39;00marg_string\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     43\u001b[0m         \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m,\n\u001b[1;32m     44\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m     45\u001b[0m     )\n\u001b[0;32m---> 46\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mzip\u001b[39m(_old_args, args)), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/praw/reddit.py:963\u001b[0m, in \u001b[0;36mReddit.request\u001b[0;34m(self, data, files, json, method, params, path)\u001b[0m\n\u001b[1;32m    961\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ClientException(msg)\n\u001b[1;32m    962\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 963\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_core\u001b[38;5;241m.\u001b[39mrequest(\n\u001b[1;32m    964\u001b[0m         data\u001b[38;5;241m=\u001b[39mdata,\n\u001b[1;32m    965\u001b[0m         files\u001b[38;5;241m=\u001b[39mfiles,\n\u001b[1;32m    966\u001b[0m         json\u001b[38;5;241m=\u001b[39mjson,\n\u001b[1;32m    967\u001b[0m         method\u001b[38;5;241m=\u001b[39mmethod,\n\u001b[1;32m    968\u001b[0m         params\u001b[38;5;241m=\u001b[39mparams,\n\u001b[1;32m    969\u001b[0m         path\u001b[38;5;241m=\u001b[39mpath,\n\u001b[1;32m    970\u001b[0m     )\n\u001b[1;32m    971\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m BadRequest \u001b[38;5;28;01mas\u001b[39;00m exception:\n\u001b[1;32m    972\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/prawcore/sessions.py:328\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, path, data, files, json, params, timeout)\u001b[0m\n\u001b[1;32m    326\u001b[0m     json[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapi_type\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjson\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    327\u001b[0m url \u001b[38;5;241m=\u001b[39m urljoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_requestor\u001b[38;5;241m.\u001b[39moauth_url, path)\n\u001b[0;32m--> 328\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request_with_retries(\n\u001b[1;32m    329\u001b[0m     data\u001b[38;5;241m=\u001b[39mdata,\n\u001b[1;32m    330\u001b[0m     files\u001b[38;5;241m=\u001b[39mfiles,\n\u001b[1;32m    331\u001b[0m     json\u001b[38;5;241m=\u001b[39mjson,\n\u001b[1;32m    332\u001b[0m     method\u001b[38;5;241m=\u001b[39mmethod,\n\u001b[1;32m    333\u001b[0m     params\u001b[38;5;241m=\u001b[39mparams,\n\u001b[1;32m    334\u001b[0m     timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[1;32m    335\u001b[0m     url\u001b[38;5;241m=\u001b[39murl,\n\u001b[1;32m    336\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/prawcore/sessions.py:267\u001b[0m, in \u001b[0;36mSession._request_with_retries\u001b[0;34m(self, data, files, json, method, params, timeout, url, retry_strategy_state)\u001b[0m\n\u001b[1;32m    254\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_do_retry(\n\u001b[1;32m    255\u001b[0m         data,\n\u001b[1;32m    256\u001b[0m         files,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    264\u001b[0m         url,\n\u001b[1;32m    265\u001b[0m     )\n\u001b[1;32m    266\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mSTATUS_EXCEPTIONS:\n\u001b[0;32m--> 267\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mSTATUS_EXCEPTIONS[response\u001b[38;5;241m.\u001b[39mstatus_code](response)\n\u001b[1;32m    268\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m codes[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mno_content\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m    269\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mTooManyRequests\u001b[0m: received 429 HTTP response"
     ]
    }
   ],
   "source": [
    "get_comments_as_csv(\"UCSantaBarbara\", 1, \"top\")\n",
    "get_comments_as_csv(\"UCSD\", 1, \"top\")\n",
    "get_comments_as_csv(\"UCDavis\", 1, \"top\")\n",
    "get_comments_as_csv(\"ucla\", 1, \"top\")\n",
    "get_comments_as_csv(\"UCI\", 1, \"top\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
